# GPT OSS 120B - Quick Reference Card

## ğŸš€ Inicio RÃ¡pido

### 1. El modelo ya estÃ¡ disponible
- No requiere instalaciÃ³n
- No requiere configuraciÃ³n
- Ya estÃ¡ integrado en tu aplicaciÃ³n

### 2. CÃ³mo usarlo
```
Abre tu app â†’ Chat â†’ Selector de modelos â†’ "GPT OSS 120B" â†’ Escribe mensaje
```

### 3. Para activar razonamiento
```
Mensaje + "Usa razonamiento avanzado" â†’ Enviar
```

---

## ğŸ“Š Especificaciones Clave

| CaracterÃ­stica | Valor |
|---|---|
| **Nombre Completo** | OpenAI GPT-OSS 120B |
| **ID en API** | `openai/gpt-oss-120b` |
| **Proveedor** | Groq LPU |
| **Velocidad** | ~500 tokens/segundo âš¡ |
| **Contexto** | 131,072 tokens (131K) |
| **Output MÃ¡ximo** | 65,536 tokens (65K) |
| **Razonamiento** | âœ… Habilitado |
| **BÃºsqueda Web** | âœ… Integrada |
| **MultilingÃ¼e** | âœ… 81+ idiomas |
| **Costo por 1M tokens** | Input: $0.15 / Output: $0.60 |
| **Disponibilidad** | Usuarios FREE y PREMIUM |

---

## ğŸ¯ Casos de Uso

### Excelente Para
âœ… Razonamiento complejo  
âœ… Documentos grandes  
âœ… AnÃ¡lisis multilingÃ¼e  
âœ… ProgramaciÃ³n competitiva  
âœ… BÃºsqueda + anÃ¡lisis  
âœ… Aplicaciones de producciÃ³n  

### No Ideal Para
âŒ Procesamiento de imÃ¡genes (no soporta)  
âŒ Respuestas muy cortas (overkill)  
âŒ Contexto < 5K tokens (usa Llama 3.3)  

---

## ğŸ’¡ Ejemplos de Uso

### Ejemplo 1: Razonamiento
```
Usuario: "Â¿CÃ³mo optimizarÃ­a un algoritmo O(nÂ²)?"

Modelo muestra:
1ï¸âƒ£ [THINKING] "Primero debo analizar el algoritmo..."
2ï¸âƒ£ [THINKING] "Las opciones son: divide y conquista, DP, binary search..."
3ï¸âƒ£ [RESPONSE] "La mejor soluciÃ³n es merge sort con O(n log n)..."
```

### Ejemplo 2: Documento Grande
```
Usuario: [Pega 30,000 palabras de un PDF] "Â¿CuÃ¡les son los puntos clave?"

Respuesta: AnÃ¡lisis completo sin truncarse (131K lo permite)
```

### Ejemplo 3: BÃºsqueda Web
```
Usuario: "Â¿CuÃ¡les son las Ãºltimas noticias de IA?"

DetecciÃ³n automÃ¡tica â†’ Busca web reciente â†’ Respuesta actualizada
```

---

## âš™ï¸ ConfiguraciÃ³n Recomendada

### Para MÃ¡ximo Razonamiento
```typescript
{
  model: "gpt-oss-120b",
  useReasoning: true,
  temperature: 0.3,  // MÃ¡s determinista
  chatMode: "general"
}
```

### Para MÃ¡xima Velocidad
```typescript
{
  model: "gpt-oss-120b",
  useReasoning: false,
  temperature: 0.7,  // Normal
  chatMode: "general"
}
```

### Para Documentos
```typescript
{
  model: "gpt-oss-120b",
  useReasoning: false,
  chatMode: "general"
  // Sin razonamiento = mÃ¡xima capacidad de contexto
}
```

---

## ğŸ“ˆ Benchmarks del Modelo

| Prueba | Resultado | vs Competencia |
|---|---|---|
| MMLU (Razonamiento) | 90.0% | âœ… Muy bueno |
| SWE-Bench (CÃ³digo) | 62.4% | âœ… Competitivo |
| HealthBench (Salud) | 57.6% | âœ… Muy bueno |
| MMMLU (MultilingÃ¼e) | 81.3% | âœ… Excelente |

---

## ğŸ’° EstimaciÃ³n de Costos

### ConversaciÃ³n TÃ­pica
```
Input:  500 tokens Ã— $0.15/1M = $0.000075
Output: 200 tokens Ã— $0.60/1M = $0.00012
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:  $0.000195 (~0.2 de centavo)
```

### Comparativa Anual (1000 conversaciones)
```
GPT OSS 120B:  $0.195  ğŸ˜± Ultra barato
GPT-4o:        $1.50   ğŸ’¸ 7.7x mÃ¡s caro
Claude 3.5:    $2.00   ğŸ’¸ 10x mÃ¡s caro
```

---

## ğŸ”§ Archivos Modificados

### server/routes.ts
- **LÃ­nea 138-154:** DefiniciÃ³n del modelo
- **LÃ­nea 851-861:** Soporte de razonamiento
- **LÃ­nea 933-936:** Captura de pensamiento

### AutomÃ¡ticamente Funciona
- `client/src/components/chat/ChatInput.tsx` - Selector de modelos
- `client/src/pages/ChatPage.tsx` - Carga de modelos
- `/api/models` endpoint - Devuelve el nuevo modelo
- `/api/chat` endpoint - Soporta el modelo

---

## ğŸš¨ Troubleshooting RÃ¡pido

| Problema | SoluciÃ³n |
|---|---|
| No aparece en selector | Reinicia navegador, Ctrl+Shift+Del |
| Error de API | Verifica variable `grokAPI` en .env |
| Respuestas lentas | Normal si razonamiento activado |
| Respuesta truncada | EstÃ¡s en lÃ­mite de 65K, reduce contexto |
| Razonamiento no muestra | Activa `useReasoning: true` |

---

## âœ¨ CaracterÃ­sticas Pendientes (Futuro)

ğŸ”„ Tool Use (funciones)  
ğŸ”„ JSON Schema (respuestas estructuradas)  
ğŸ”„ Prompt caching (ahorrar dinero)  
ğŸ”„ UI visual para razonamiento  

**Nota:** El modelo ya funciona perfecto sin estas.

---

## ğŸ“š DocumentaciÃ³n Completa

| Documento | PropÃ³sito |
|---|---|
| **GPT_OSS_120B_SETUP.md** | InformaciÃ³n tÃ©cnica detallada |
| **HOW_TO_USE_GPT_OSS.md** | GuÃ­a de usuario exhaustiva |
| **GPT_OSS_ADVANCED_FEATURES.md** | Features futuras y roadmap |
| **GPT_OSS_VERIFICATION_CHECKLIST.md** | Checklist de implementaciÃ³n |
| **GPT_OSS_QUICK_REFERENCE.md** | Este documento |

---

## ğŸ“ Comparativa vs Otros Modelos en tu App

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aspecto         â”‚ GPT OSS  â”‚ Llama    â”‚ Qwen Coder     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Velocidad       â”‚ 500 tps  â”‚ 500 tps  â”‚ 300 tps        â”‚
â”‚ Contexto        â”‚ 131K     â”‚ 128K     â”‚ 262K â­        â”‚
â”‚ Razonamiento    â”‚ âœ…       â”‚ âŒ       â”‚ âŒ             â”‚
â”‚ MultilingÃ¼e     â”‚ 81 langs â”‚ Bueno    â”‚ Limitado       â”‚
â”‚ ProgramaciÃ³n    â”‚ 62.4%    â”‚ Excelenteâ”‚ Especializadoâ­â”‚
â”‚ Costo           â”‚ Barato   â”‚ Barato   â”‚ Barato         â”‚
â”‚ Premium Only    â”‚ âŒ       â”‚ âŒ       â”‚ âŒ             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Usa:
- GPT OSS 120B: General, razonamiento, multilingÃ¼e
- Llama 3.3: ProgramaciÃ³n rÃ¡pida
- Qwen Coder: SOLO cÃ³digo
```

---

## ğŸ¯ Checklist de VerificaciÃ³n

- [x] Modelo definido en servidor
- [x] Razonamiento implementado
- [x] Streaming funcionando
- [x] BÃºsqueda web integrada
- [x] Contexto de 131K activo
- [x] Output mÃ¡ximo 65K
- [x] CompilaciÃ³n sin errores
- [x] Aparece en UI automÃ¡ticamente
- [x] API routes soportan modelo
- [x] DocumentaciÃ³n completa

**ESTADO: LISTO PARA PRODUCCIÃ“N âœ…**

---

## ğŸš€ Â¿QuÃ© Viene DespuÃ©s?

### Corto Plazo (Hoy)
1. Abre tu app
2. Selecciona GPT OSS 120B
3. Prueba un mensaje

### Mediano Plazo
1. Ajusta prompts segÃºn tus necesidades
2. Monitorea costos (probablemente mÃ­nimos)
3. Considera agregar Tool Use si necesitas

### Largo Plazo
1. UI visual para razonamiento
2. Analytics de uso
3. OptimizaciÃ³n de prompts

---

## ğŸ“ Soporte RÃ¡pido

**DocumentaciÃ³n Oficial:**
- https://console.groq.com/docs/model/openai/gpt-oss-120b
- https://openai.com/index/gpt-oss-model-card/

**Obtener API Key:**
- https://console.groq.com/keys

**Tu AplicaciÃ³n:**
- Variable: `grokAPI` en `.env`

---

**Â¡Tu modelo GPT OSS 120B estÃ¡ 100% listo! ğŸ‰**
